{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-714 Final Project: Pre-training with NEEDLE\n",
    "NEEDLE is a self-contained deep learning framework that supports training and inference with a variety of modern neural networks. Throughout this course, we have implemented several different neural network architectures, including feed-forward, convolutional, and recurrent networks. Another key function of this framework is the ability to use pretrained network weights. In this project, we propose to implement the following two features:\n",
    "\n",
    "1. Save and load weights with NEEDLE\n",
    "2. Port external models to a NEEDLE model. In order to support as many frameworks as possible, instead of implementing individual converters for each framework, we will implement a conversion pipeline that takes an ONNX model as input and converts it to a NEEDLE model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Save/Load weights with NEEDLE\n",
    "In this section, we refer to \"model\" as any architecture that inherit the `ndl.nn.Module` class. The first feature of NEEDLE is the ability to save and load model weights. This process is split into two steps: saving and loading.\n",
    "\n",
    "To save the weights, we simply iterate through all the parameters in the model, create signature for them, and save them to a file. \n",
    "\n",
    "Loading the weights is a bit more complicated, as we need to ensure that the target model has the same architecture as the model from which the weights were saved. We need to compare the signature of the models, and device of the models. If both match, we load the weights corresondingly. Otherwise, we raise an error.\n",
    "\n",
    "Once the signatures have been verified, we can load the weights from the file and assign them to the corresponding parameters in the target model. This ensures that the weights are applied correctly, allowing the model to continue making predictions using the loaded weights.\n",
    "\n",
    "Now we explain the implementation step by step.\n",
    "\n",
    "### Description\n",
    "#### Save weights\n",
    "1. Create a signature for the parameters and the model (i.e., the ndl.nn.Module object). The state_dict() function creates a signature for each parameter and stores them in a dictionary that maps the signature to its corresponding value. The id() function creates a signature for the model that describes its architecture. Note that instead of using the name of each parameter, we manually name the parameters with a counter. This avoids the problem of two models with the same architecture having different names for their parameters.\n",
    "    ```python\n",
    "    def state_dict(self, prefix=\"\"):\n",
    "        \"\"\"Return a dictionary of the module's parameters.\"\"\"\n",
    "        # Create an empty dictionary to store the state of the model\n",
    "        state_dict = {}\n",
    "        # Create a counter for each module's class name\n",
    "        count = Counter()\n",
    "        \n",
    "        # Iterate through all the attributes of the module\n",
    "        for k, v in self.__dict__.items():\n",
    "            # If the attribute is a parameter, add it to the dictionary\n",
    "            if isinstance(v, Parameter):\n",
    "                name = k\n",
    "                state_dict[prefix + name] = v\n",
    "            # If the attribute is a module, increment the counter and add the module and its parameters to the dictionary\n",
    "            elif isinstance(v, Module):\n",
    "                count[v.__class__.__name__] += 1\n",
    "                name = v.__class__.__name__ + '-' + str(count[v.__class__.__name__])\n",
    "                state_dict.update(v.state_dict(prefix + name + \".\"))\n",
    "        return state_dict\n",
    "    ```\n",
    "\n",
    "    ```python\n",
    "    def id(self):\n",
    "        \"\"\"construct a json string that uniquely identifies the module.\"\"\"\n",
    "        # Create a counter for each module's class name\n",
    "        count = Counter()\n",
    "\n",
    "        # Create a dictionary to store the signatures of the module's parameters\n",
    "        signatures = dict()\n",
    "        \n",
    "        # Add the class name of the module to the dictionary\n",
    "        signatures[self.__class__.__name__] = dict()\n",
    "        \n",
    "        # Set the current dictionary to the inner dictionary that was just created\n",
    "        signatures = signatures[self.__class__.__name__]\n",
    "        \n",
    "        # Iterate through the attributes of the module\n",
    "        for k, v in self.__dict__.items():\n",
    "            # If the attribute is a module, increment the counter and add its signature to the dictionary\n",
    "            if isinstance(v, Module):\n",
    "                count[v.__class__.__name__] += 1\n",
    "                name = v.__class__.__name__ + '-' + str(count[v.__class__.__name__])\n",
    "                signatures[name] = v.id()\n",
    "            # If the attribute is a parameter, add its shape to the dictionary\n",
    "            elif isinstance(v, Parameter):\n",
    "                name = k\n",
    "                signatures[name] = v.shape\n",
    "            # If the attribute is a list or tuple, iterate through its elements\n",
    "            # and add the signatures of the modules and parameters to the dictionary\n",
    "            elif isinstance(v, (list, tuple)):\n",
    "                for i, x in enumerate(v):\n",
    "                    if isinstance(x, Module):\n",
    "                        count[x.__class__.__name__] += 1\n",
    "                        name = x.__class__.__name__ + '-' + str(count[x.__class__.__name__])\n",
    "                        signatures[name] = x.id()\n",
    "                    elif isinstance(x, Parameter):\n",
    "                        name = k\n",
    "                        signatures[name] = x.shape\n",
    "        # Return the dictionary containing the signatures of the module's parameters\n",
    "        return signatures\n",
    "    ```\n",
    "\n",
    "2. Save the `state_dict` to a `.npy` file. We also save the `device` of the model.\n",
    "\n",
    "\n",
    "    ```python\n",
    "    def save_state_dict(module, filename):\n",
    "        \"\"\"\n",
    "        Save the state dict of a module to a file.\n",
    "\n",
    "        Args:\n",
    "            module (ndl.nn.Module): The module to save.\n",
    "            filename (str): The file to save to.\n",
    "        \"\"\"\n",
    "        # Create a dictionary to store the state dict and signature of the module\n",
    "        save_dict = {}\n",
    "        save_dict['state_dict'] = module.state_dict()\n",
    "\n",
    "        # Convert the state dict to numpy arrays and store them in the dictionary\n",
    "        for k, v in save_dict['state_dict'].items():\n",
    "            save_dict['state_dict'][k] = v.numpy().astype(np.float32)\n",
    "        # Store the signature of the module in the dictionary\n",
    "        save_dict['signature'] = str(module.id())\n",
    "\n",
    "        # Store the device of the module in the dictionary\n",
    "        save_dict['device'] = str(module.device)\n",
    "\n",
    "        # Save the dictionary to the specified file using numpy\n",
    "        np.save(filename, save_dict)\n",
    "        print(\"Saved state dict to file: {}\".format(filename))\n",
    "    ```\n",
    "\n",
    "#### Load weights\n",
    "Compare the signature of the target model and source model. Then, load the `state_dict` into the model by matching the parameter signatures\n",
    "\n",
    "```python\n",
    "def load_state_dict(module, filename):\n",
    "    \"\"\"\n",
    "    Load the state dict from a file.\n",
    "\n",
    "    Args:\n",
    "        module: (ndl.nn.Module): The module to load the state dict to.\n",
    "        filename (str): The file to load state dict from.\n",
    "    \"\"\"\n",
    "    # Load the dictionary containing the state dict and signature of the module from the file\n",
    "    save_dict = np.load(filename, allow_pickle=True).item()\n",
    "\n",
    "    # Check if the signature of the loaded module matches the saved state dict\n",
    "    assert save_dict['signature'] == str(module.id()), \"Module signature does not match saved state dict\"\n",
    "\n",
    "    # Check if the device of the loaded module matches the saved state dict\n",
    "    assert save_dict['device'] == str(module.device), \"Module device does not match saved state dict\"\n",
    "\n",
    "    # Load the state dict to the module\n",
    "    module.load_state_dict(save_dict['state_dict'])\n",
    "\n",
    "    # Print a message to indicate that the state dict has been loaded from the file\n",
    "    print(\"Loaded state dict from file: {}\".format(filename))\n",
    "```\n",
    "\n",
    "and `module.load_state_dict()` function:\n",
    "\n",
    "```python\n",
    "def load_state_dict(self, state_dict):\n",
    "    \"\"\"\n",
    "    Iterate over the module's parameters and submodules and load the values from the  state_dict.\n",
    "    \n",
    "    Args:\n",
    "        state_dict (dict): A dictionary containing the values to load.\n",
    "    \"\"\"\n",
    "    # Get a dictionary of the module's parameters\n",
    "    this = self.state_dict()\n",
    "    # Iterate through the values in the state_dict\n",
    "    for k, v in state_dict.items():\n",
    "        # If the value is a parameter of the module, set its value to the value from the state_dict\n",
    "        if k in this:\n",
    "            this[k].data = Tensor(NDArray(v, device=self.device), device=self.device, requires_grad=True)\n",
    "        else:\n",
    "            # If the value is not a parameter of the module, raise an error\n",
    "            raise KeyError(\"State dict does not contain key: \" + k)\n",
    "```\n",
    "\n",
    "#### Model Summary\n",
    "As a side product of the above functions, we can also create a model summary function that prints out the model's architecture and the shape of its parameters. This is useful for debugging and understanding the model's architecture. The summary is in the format of a json string. \n",
    "\n",
    "```python\n",
    "def summary(self):\n",
    "    \"\"\"Print a summary of the module.\"\"\"\n",
    "    id = self.id()\n",
    "    pp = pprint.PrettyPrinter(indent=2)\n",
    "    pp.pprint(id)\n",
    "    return json.dumps(id)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo\n",
    "####  Save/Load weights\n",
    "In this section, we demonstrate NEEDLE's save/load weights functionality with live code blocks. Here we use a ResNet9 model we developed during HW4, but in theory any model is supported as the save/load are implemented for the base `ndl.nn.Module` class.\n",
    "\n",
    "We start by importing the necessary libraries and defining the ResNet9 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<module 'needle.backend_ndarray' from './python/needle/backend_ndarray/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "from apps.models import ResNet9\n",
    "import numpy as np \n",
    "import needle as ndl\n",
    "from needle.autograd import Tensor\n",
    "\n",
    "model = ResNet9(device=ndl.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The saving of the model's weights is done by calling the `ndl.save_state_dict()` function. We use the numpy object array as a medium of saved data. Note that both the model weights and device information are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved state dict to file: weights.npy\n"
     ]
    }
   ],
   "source": [
    "ndl.save_state_dict(model, 'weights.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate the loading of the model's weights, we create a new model and load the saved weights into it. We then compare the weights of the two models to show that they are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = ResNet9(device=ndl.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before loading the weights, `model` and `new_model` have different weights, thus different output. Let's test that out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "As expected, the two models have different outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[39m=\u001b[39m Tensor(np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandn(\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m32\u001b[39m)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32), device\u001b[39m=\u001b[39mndl\u001b[39m.\u001b[39mcpu())\n\u001b[0;32m----> 3\u001b[0m \u001b[39massert\u001b[39;00m np\u001b[39m.\u001b[39mallclose(model(x)\u001b[39m.\u001b[39mnumpy(), new_model(x)\u001b[39m.\u001b[39mnumpy()), \u001b[39m'\u001b[39m\u001b[39mAs expected, the two models have different outputs\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: As expected, the two models have different outputs"
     ]
    }
   ],
   "source": [
    "x = Tensor(np.random.randn(1, 3, 32, 32).astype(np.float32), device=ndl.cpu())\n",
    "\n",
    "assert np.allclose(model(x).numpy(), new_model(x).numpy()), 'As expected, the two models have different outputs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the weights we just saved into `new_model`. We can see that the weights of `model` and `new_model` are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded state dict from file: weights.npy\n",
      "Loading Success! The models now have same outputs\n"
     ]
    }
   ],
   "source": [
    "ndl.load_state_dict(new_model, 'weights.npy')\n",
    "\n",
    "assert np.allclose(model(x).numpy(), new_model(x).numpy()), 'The two models have different outputs'\n",
    "\n",
    "print('Loading Success! The models now have same outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, they now have the same output.\n",
    "\n",
    "But things could get complicated if we have various models of different architecture. In these cases we want to prevent the model from loading weights that are not compatible with its architecture. We have set up a check to ensure that the model's signature matches the signature of the saved weights. If the signatures do not match, an error will be raised. We also prevent the model from loading weights that are saved on a different device.\n",
    "\n",
    "Here we define a `ResNet9_2` model, which is very similar to `ResNet9` but has different shapes in some layers. We then try to load the weights of `ResNet9` into `ResNet9_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Module signature does not match saved state dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mapps\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m ResNet9_2\n\u001b[1;32m      3\u001b[0m differnt_model \u001b[39m=\u001b[39m ResNet9_2(device\u001b[39m=\u001b[39mndl\u001b[39m.\u001b[39mcpu())\n\u001b[0;32m----> 5\u001b[0m ndl\u001b[39m.\u001b[39;49mload_state_dict(differnt_model, \u001b[39m'\u001b[39;49m\u001b[39mweights.npy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/projects/hw4/python/needle/save_load.py:44\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(module, filename)\u001b[0m\n\u001b[1;32m     41\u001b[0m save_dict \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(filename, allow_pickle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     43\u001b[0m \u001b[39m# Check if the signature of the loaded module matches the saved state dict\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[39massert\u001b[39;00m save_dict[\u001b[39m'\u001b[39m\u001b[39msignature\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mstr\u001b[39m(module\u001b[39m.\u001b[39mid()), \u001b[39m\"\u001b[39m\u001b[39mModule signature does not match saved state dict\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[39m# Check if the device of the loaded module matches the saved state dict\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39massert\u001b[39;00m save_dict[\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mstr\u001b[39m(module\u001b[39m.\u001b[39mdevice), \u001b[39m\"\u001b[39m\u001b[39mModule device does not match saved state dict\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Module signature does not match saved state dict"
     ]
    }
   ],
   "source": [
    "from apps.models import ResNet9_2\n",
    "\n",
    "differnt_model = ResNet9_2(device=ndl.cpu())\n",
    "\n",
    "ndl.load_state_dict(differnt_model, 'weights.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And similarly, we test loading to a different device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Module device does not match saved state dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m cuda_model \u001b[39m=\u001b[39m ResNet9(device\u001b[39m=\u001b[39mndl\u001b[39m.\u001b[39mcuda())\n\u001b[0;32m----> 3\u001b[0m ndl\u001b[39m.\u001b[39;49mload_state_dict(cuda_model, \u001b[39m'\u001b[39;49m\u001b[39mweights.npy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/projects/hw4/python/needle/save_load.py:47\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(module, filename)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39massert\u001b[39;00m save_dict[\u001b[39m'\u001b[39m\u001b[39msignature\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mstr\u001b[39m(module\u001b[39m.\u001b[39mid()), \u001b[39m\"\u001b[39m\u001b[39mModule signature does not match saved state dict\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[39m# Check if the device of the loaded module matches the saved state dict\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m \u001b[39massert\u001b[39;00m save_dict[\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mstr\u001b[39m(module\u001b[39m.\u001b[39mdevice), \u001b[39m\"\u001b[39m\u001b[39mModule device does not match saved state dict\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[39m# Load the state dict to the module\u001b[39;00m\n\u001b[1;32m     50\u001b[0m module\u001b[39m.\u001b[39mload_state_dict(save_dict[\u001b[39m'\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mAssertionError\u001b[0m: Module device does not match saved state dict"
     ]
    }
   ],
   "source": [
    "cuda_model = ResNet9(device=ndl.cuda())\n",
    "\n",
    "ndl.load_state_dict(cuda_model, 'weights.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last functionality we want to demonstrate in this section is model summary, which gives us an overview fo the model's architecture and the shape of its parameters. Similar functionality is also available in PyTorch and Tensorflow, which can be really handy for debugging.\n",
    "\n",
    "For demo purpose, we examine the summary of `ResNet9` and `ResNet9_2` models. And understand why the loading should fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'ConvBN-1': { 'BatchNorm2d-1': {'bias': (16,), 'weight': (16,)},\n",
      "                'Conv-1': {'bias': (16,), 'weight': (7, 7, 3, 16)},\n",
      "                'ReLU-1': {}},\n",
      "  'ConvBN-2': { 'BatchNorm2d-1': {'bias': (32,), 'weight': (32,)},\n",
      "                'Conv-1': {'bias': (32,), 'weight': (3, 3, 16, 32)},\n",
      "                'ReLU-1': {}},\n",
      "  'ConvBN-3': { 'BatchNorm2d-1': {'bias': (64,), 'weight': (64,)},\n",
      "                'Conv-1': {'bias': (64,), 'weight': (3, 3, 32, 64)},\n",
      "                'ReLU-1': {}},\n",
      "  'ConvBN-4': { 'BatchNorm2d-1': {'bias': (128,), 'weight': (128,)},\n",
      "                'Conv-1': {'bias': (128,), 'weight': (3, 3, 64, 128)},\n",
      "                'ReLU-1': {}},\n",
      "  'Flatten-1': {},\n",
      "  'Linear-1': {'bias': (1, 128), 'weight': (128, 128)},\n",
      "  'Linear-2': {'bias': (1, 10), 'weight': (128, 10)},\n",
      "  'ReLU-1': {},\n",
      "  'Residual-1': { 'Sequential-1': { 'ConvBN-1': { 'BatchNorm2d-1': { 'bias': ( 32,),\n",
      "                                                                     'weight': ( 32,)},\n",
      "                                                  'Conv-1': { 'bias': (32,),\n",
      "                                                              'weight': ( 3,\n",
      "                                                                          3,\n",
      "                                                                          32,\n",
      "                                                                          32)},\n",
      "                                                  'ReLU-1': {}},\n",
      "                                    'ConvBN-2': { 'BatchNorm2d-1': { 'bias': ( 32,),\n",
      "                                                                     'weight': ( 32,)},\n",
      "                                                  'Conv-1': { 'bias': (32,),\n",
      "                                                              'weight': ( 3,\n",
      "                                                                          3,\n",
      "                                                                          32,\n",
      "                                                                          32)},\n",
      "                                                  'ReLU-1': {}}}},\n",
      "  'Residual-2': { 'Sequential-1': { 'ConvBN-1': { 'BatchNorm2d-1': { 'bias': ( 128,),\n",
      "                                                                     'weight': ( 128,)},\n",
      "                                                  'Conv-1': { 'bias': (128,),\n",
      "                                                              'weight': ( 3,\n",
      "                                                                          3,\n",
      "                                                                          128,\n",
      "                                                                          128)},\n",
      "                                                  'ReLU-1': {}},\n",
      "                                    'ConvBN-2': { 'BatchNorm2d-1': { 'bias': ( 128,),\n",
      "                                                                     'weight': ( 128,)},\n",
      "                                                  'Conv-1': { 'bias': (128,),\n",
      "                                                              'weight': ( 3,\n",
      "                                                                          3,\n",
      "                                                                          128,\n",
      "                                                                          128)},\n",
      "                                                  'ReLU-1': {}}}}}\n"
     ]
    }
   ],
   "source": [
    "_ = model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'ConvBN-1': { 'BatchNorm2d-1': {'bias': (16,), 'weight': (16,)},\n",
      "                'Conv-1': {'bias': (16,), 'weight': (7, 7, 3, 16)},\n",
      "                'ReLU-1': {}},\n",
      "  'ConvBN-2': { 'BatchNorm2d-1': {'bias': (32,), 'weight': (32,)},\n",
      "                'Conv-1': {'bias': (32,), 'weight': (3, 3, 16, 32)},\n",
      "                'ReLU-1': {}},\n",
      "  'ConvBN-3': { 'BatchNorm2d-1': {'bias': (64,), 'weight': (64,)},\n",
      "                'Conv-1': {'bias': (64,), 'weight': (3, 3, 32, 64)},\n",
      "                'ReLU-1': {}},\n",
      "  'ConvBN-4': { 'BatchNorm2d-1': {'bias': (64,), 'weight': (64,)},\n",
      "                'Conv-1': {'bias': (64,), 'weight': (3, 3, 64, 64)},\n",
      "                'ReLU-1': {}},\n",
      "  'Flatten-1': {},\n",
      "  'Linear-1': {'bias': (1, 64), 'weight': (64, 64)},\n",
      "  'Linear-2': {'bias': (1, 10), 'weight': (64, 10)},\n",
      "  'ReLU-1': {},\n",
      "  'Residual-1': { 'Sequential-1': { 'ConvBN-1': { 'BatchNorm2d-1': { 'bias': ( 32,),\n",
      "                                                                     'weight': ( 32,)},\n",
      "                                                  'Conv-1': { 'bias': (32,),\n",
      "                                                              'weight': ( 3,\n",
      "                                                                          3,\n",
      "                                                                          32,\n",
      "                                                                          32)},\n",
      "                                                  'ReLU-1': {}},\n",
      "                                    'ConvBN-2': { 'BatchNorm2d-1': { 'bias': ( 32,),\n",
      "                                                                     'weight': ( 32,)},\n",
      "                                                  'Conv-1': { 'bias': (32,),\n",
      "                                                              'weight': ( 3,\n",
      "                                                                          3,\n",
      "                                                                          32,\n",
      "                                                                          32)},\n",
      "                                                  'ReLU-1': {}}}},\n",
      "  'Residual-2': { 'Sequential-1': { 'ConvBN-1': { 'BatchNorm2d-1': { 'bias': ( 64,),\n",
      "                                                                     'weight': ( 64,)},\n",
      "                                                  'Conv-1': { 'bias': (64,),\n",
      "                                                              'weight': ( 3,\n",
      "                                                                          3,\n",
      "                                                                          64,\n",
      "                                                                          64)},\n",
      "                                                  'ReLU-1': {}},\n",
      "                                    'ConvBN-2': { 'BatchNorm2d-1': { 'bias': ( 64,),\n",
      "                                                                     'weight': ( 64,)},\n",
      "                                                  'Conv-1': { 'bias': (64,),\n",
      "                                                              'weight': ( 3,\n",
      "                                                                          3,\n",
      "                                                                          64,\n",
      "                                                                          64)},\n",
      "                                                  'ReLU-1': {}}}}}\n"
     ]
    }
   ],
   "source": [
    "_ = differnt_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at `Residual-2.Sequential-1.ConvBN-1.BatchNorm2d-1`, we coudl see that  `ResNet9` has 128 channels in the first layer, while `ResNet9_2` has 64 channels. This is why the loading should fail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Port ONNX models to NEEDLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the lack of training optimization (like operator optimization, distributed training), it's often hard to train a large scale model for multiple epoch on Needle directly. In order to enable Needle to run inference on large scale model, we support Needle to load pre-trained model from other ML framework like PyTorch, Tensorflow, Caffe etc. \n",
    "\n",
    "Instead of building seperate model loader for each ML framework individually, we only implement the convert from ONNX to Needle. ONNX is an widely use open format supporting model transfer between multiple ML framework like PyTorch, Tensorflow, Caffe etc, thus could be a good intermediate to bridge the convertion between Needle and other common ML framework.\n",
    "\n",
    "In order to load ONNX model to Needle. We need to  1). Load the protocol buffer stored in onnx model file and use a parser to extract each module, their input / output variable names, and weights. 2). Using the intermediate variable, we can construct a graph with those module, and use topological sort to iterate through the graph to transfer each of the intermediate variable to Needle.nn modules. 3). We could construct the target needle model from needle modules dynamically.\n",
    "\n",
    "We will introduce each step in order.\n",
    "\n",
    "### Description\n",
    "#### Parse ONNX module to Dictionary\n",
    "There's a specific rule of how ONNX store model. Specifically, onnx.node store all the operation graph between each module(like input, output, attribute value, and name of weight and bias), and onnx.initializer store all the vale of weight and bias corredsponding to the name in onnx.node. \n",
    "\n",
    "\n",
    "Thus, likewise, we construct some object to store the value parse from ONNX model. For which Onnx node is similar to what onnx.node is doing, which record all the connection between different data, while onnx data is similar to onnx.data, which store all the actual value of data.\n",
    "\n",
    "Moreover, we will construct a object inheritance from onnx node for each operator in the onnx.node, please refer to onnx_dict.py for detail.\n",
    "\n",
    "```python\n",
    "class OnnxNode:\n",
    "    def __init__(self, att_dict) -> None:\n",
    "        self.name = att_dict['name']\n",
    "        self.inputs = att_dict['inputs']\n",
    "        self.indegree = len(self.inputs)\n",
    "        for input_name in self.inputs:\n",
    "            if \"data\" in input_name:\n",
    "                self.indegree -= 1\n",
    "        self.output: str = att_dict['output']\n",
    "\n",
    "\n",
    "class OnnxData:\n",
    "    def __init__(self, **kwargs) -> None:\n",
    "        self.name = kwargs['name']\n",
    "        self.dtype = kwargs['dtype']\n",
    "        self.category = \"Initializer\"   \n",
    "        self.data: np.array = kwargs['data']\n",
    "        self.dims: list =kwargs['dims']\n",
    "\n",
    "\n",
    "class ConvOpNode(OnnxNode):\n",
    "    def __init__(self, att_dict) -> None:\n",
    "        super().__init__(att_dict)\n",
    "        \n",
    "        # attribures\n",
    "        self.dilations = att_dict[\"dilations\"]\n",
    "        self.group = att_dict[\"group\"]\n",
    "        self.kernel_shape = att_dict[\"kernel_shape\"]\n",
    "        self.padding = att_dict[\"pads\"]\n",
    "        self.strides = att_dict[\"strides\"]\n",
    "        \n",
    "        # data field\n",
    "        self.X_name = att_dict[\"X_name\"]\n",
    "        self.Y_name = att_dict[\"Y_name\"]\n",
    "        self.W_name = att_dict[\"W_name\"]\n",
    "        self.W: OnnxData = att_dict[\"W_data\"]\n",
    "        self.use_bias = False\n",
    "        if \"B_name\" in att_dict:\n",
    "            self.use_bias = True\n",
    "            self.B_name = att_dict[\"B_name\"]\n",
    "            self.B: OnnxData = att_dict[\"B_data\"]\n",
    "\n",
    "        self.out_channels, self.in_channels, _, _ = self.W.dims\n",
    "        \n",
    "class BatchNorm2DNode(OnnxNode):\n",
    "    def __init__(self, att_dict) -> None:\n",
    "        super().__init__(att_dict)\n",
    "\n",
    "        # attribures\n",
    "        self.eps = att_dict[\"epsilon\"]\n",
    "        self.momentum = att_dict[\"momentum\"]\n",
    "        self.spatial = att_dict[\"spatial\"]\n",
    "\n",
    "        # data field\n",
    "        self.X_name = att_dict[\"X_name\"]\n",
    "        self.gamma_name = att_dict[\"gamma_name\"]\n",
    "        self.gamma: OnnxData = att_dict[\"gamma_data\"]\n",
    "        self.beta_name = att_dict[\"beta_name\"]\n",
    "        self.beta: OnnxData = att_dict[\"beta_data\"]\n",
    "        self.running_mean_name = att_dict[\"running_mean_name\"]\n",
    "        self.running_mean: OnnxData = att_dict[\"running_mean_data\"]\n",
    "        self.running_var_name = att_dict[\"running_var_name\"]\n",
    "        self.running_var: OnnxData = att_dict[\"running_var_data\"]\n",
    "        self.Y_name = att_dict[\"Y_name\"]\n",
    "\n",
    "        self.dim = self.gamma.dims[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### demo\n",
    "In this small demo, we create a Residual block consisting of Conv, Batchnorm, ReLU and residual connection, as we can see the Needle model from ONNX produced the same output as the PyTorch model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix \n",
    "In this section, we breifly discuss how to convert a PyTorch model to ONNX model. Although our focus of this project is to convert ONNX model to Needle, ONNX are mostly used for moving models  between different tools and frameworks for training, optimizing, and deploying them instead of building a model from scratch. Thus, for the sake of completeness, we will breifly discuss how to build a PyTorch model and convert it to ONNX model. Here, we demonstrate with two examples, one is a pretrained ResNet model offered by torchvision, and the other is a simple RNN model we build from scratch. Note that this section heavily relies on the official PyTorch documentation.\n",
    "\n",
    "### Using Pretrained Model from torchvision\n",
    "Here we demonstrate how to use a pretrained ResNet18 model from torchvision. The model is pretrained on the ImageNet dataset.\n",
    "\n",
    "```python\n",
    "# import the resnet18 model from PyTorch's torchvision module\n",
    "from torchvision.models import resnet18 \n",
    "import torch\n",
    "\n",
    "# create a resnet18 model and load it with pre-trained weights\n",
    "model = resnet18(pretrained=True) \n",
    "\n",
    "# Specify the input and output names of the onnx model\n",
    "input_names = ['data'] \n",
    "output_names = ['output']\n",
    "\n",
    "# create a dummy input tensor used to trace the model\n",
    "dummy_input = torch.randn(1, 3, 224, 224, device='cpu') \n",
    "\n",
    "# export the model to ONNX format\n",
    "torch.onnx.export(model, dummy_input, 'resnet18.onnx', verbose=True, input_names=input_names, output_names=output_names) \n",
    "```\n",
    "\n",
    "### Build a model from scratch\n",
    "The process of building a model from scratch is similar to the process of importing a pretrained model from torchvision. We define a simple RNN model with specified embedding size, output size, hidden size and number of layers\n",
    "The model is composed of an embedding layer, an RNN layer and a fully connected layer, similar to what we built in hw4\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SequenceModel(nn.Module):\n",
    "    def __init__(self, embedding_size, output_size, hidden_size, num_layers=1, device='cpu', dtype=torch.float32):\n",
    "        self.embedding_size = embedding_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        self.rnn = nn.RNN(embedding_size, hidden_size, num_layers=num_layers, bidirectional=False, dropout=0)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len, batch_size = x.shape\n",
    "        x = self.embedding(x)\n",
    "        x, h = self.rnn(x)\n",
    "\n",
    "        x = x.view(seq_len * batch_size, -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Instantiate the model we just defined\n",
    "model = SequenceModel(embedding_size=10, output_size=16, hidden_size=8, device='cpu')\n",
    "\n",
    "# Create a dummy input tensor used to trace the model\n",
    "x = torch.randint(0, 16, (5, 1), dtype=torch.long)\n",
    "\n",
    "# Specify the input and output names of the onnx model\n",
    "input_names = ['data']\n",
    "output_names = ['output']\n",
    "\n",
    "# Export the model to ONNX format\n",
    "torch.onnx.export(model, x, 'rnn.onnx', verbose=True, input_names=input_names, output_names=output_names)\n",
    "```\n",
    "\n",
    "We have verfied with multiple models that the exported ONNX model produce the same output as the original PyTorch model, which ensures that our corresponding Needle model will produce the same output as the original PyTorch model given it has the same output as the ONNX model. Since not a main focus of the project, the code for exporting ONNX model is not part of the submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "0a5f1a626ef7d487f5a5b34dacdf6c8beaf100eceeb0bae6631602bae8e2c4fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
